---
layout: post
title: NUGUMate
---

### Members

Chang Hee Kim, Department of Information System, Hanyang University  
Taek Joon Kim, Department of Information System, Hanyang University  
Hyun Kook Jeon, Department of Information System, Hanyang University  
Heon Nam Chu, Department of Information System, Hanyang University  

### Introduction

- Motivation

 SKT의 조사에 따르면, 1인 가구의 수가 증가함에 따라 사용자가 인공지능 스피커를 커뮤니케이션의 대상으로 생각하는 경향이 높아지고 있고, 그들이 개인적인 경험을 AI 스피커와 공유할 때 더욱 친밀감을 느낀다. 즉, 사용자는 단순한 명령 수행 및 정보 습득 뿐만 아니라, AI 스피커와 친밀한 관계를 형성하고 심리적 안정감을 얻기를 기대하고 있다.  
 본 프로젝트에서는 이러한 사용자들의 수요를 반영하여 NUGU AI 스피커와 사용자가 유대 관계를 형성하고 '친구'로서의 관계를 맺는 것을 목적으로 한다. 먼저, 사용자가 자신이 하루 동안 느꼈던 감정을 일기로 작성하면 이에 대해 감정 분석을 진행하여 각 일기의 내용을 긍정 혹은 부정으로 분류한다. 사용자가 "아리아, 오늘 하루는 어땠어?" 와 같이 발화를 시작하면, NUGU 스피커는 감정 분석 결과를 토대로 "주인님의 감정이 안 좋은 것 같아서 저도 우울했어요."처럼 사용자의 감정에 공감할 수 있는 답변을 제공한다. 이렇게 사용자로 하여금 NUGU 스피커와 상호 작용하고 있다는 느낌을 제공하여 NUGU 스피커에 대한 의존도를 높이고, NUGU 스피커의 활용 범위를 보다 확장하고자 한다.  
 
 
- NUGUMate의 작동 방식

![_config.yml]({{ site.baseurl }}/images/brief_interaction_final.png)  

 NUGUMate의 작동 방식은 아래와 같다. 
1.	사용자가 애플리케이션에 일기를 작성하면 애플리케이션은 해당 일기의 내용, 일기가 작성된 날짜, 사용자 정보를 웹 서버에 전송한다.
2.	웹 서버는 애플리케이션으로부터 받은 일기 내용을 감정 분석 모델과 연동된 모델 서버로 전송한다.
3.	감정 분석 모델을 이용하여 해당 일기에 담긴 감정을 긍정 혹은 부정으로 분류한 후, 그 결과를 웹 서버에 전달한다.
4.	이 후, 사용자가 NUGU 디바이스에 “아리아, 오늘 하루는 어땠어?” 와 같이 일상의 대화를 시작할 경우 NUGU 디바이스는 “주인님의 감정이 안 좋은 것 같아서 저도 우울했어요.” 와 같이 감정 분석 모델의 결과를 바탕으로 사용자의 감정에 공감할 수 있는 답변을 제공한다. 사용자는 조회한 날짜 당일과 더불어 조회한 날짜에 해당하는 주와 달에 대해서도 동일한 대화를 진행할 수 있다. 즉, “아리아, 이번 주는 어땠어?” 혹은 “아리아, 이번 달은 어땠어?” 와 같은 질문에 대해서도 동일한 방식의 답을 제공한다.



### Datasets
- Model용 Datasets
   감정 분석 모델을 구현하기 위해서는 우선 모델 레이어를 만들고 데이터셋을 이용하여 학습을 진행하여야 한다.
   학습 및 평가를 위한 데이터셋으로는 네이버 영화 리뷰글을 긍정적/부정적 의견으로 분류한 데이터셋(.txt 파일)을 사용하였다.
   1. ratings.txt
   
      10만개의 긍정 리뷰와 10만개의 부정 리뷰로 나누어져 있다. (총 20만개)
      각 column마다 id값, 리뷰 문장, 0(부정) 또는 1(긍정)의 결과값으로 구성되어 있다.
      
   2. ratings_train.txt
   
      총 15만개의 리뷰로 구성되어 있다. (모델 학습용)
      
   3. ratings_test.txt
   
      총 5만개의 리뷰로 구성되어 있다. (모델 평가용)

Example

| id | document | label |

|:----------|:----------|:----------|

| 9976970 | 아 더빙.. 진짜 짜증나네요 목소리 | 0 |

| 9045019 | 교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정 | 0 |

| 5403919 | 막 걸음마 뗀 3세부터 초등학교 1학년생인 8살용영화.ㅋㅋㅋ...별반개도 아까움. | 0 |

| 7797314 | 원작의 긴장감을 제대로 살려내지못했다. | 0 |

| 7156791 | 액션이 없는데도 재미 있는 몇안되는 영화 | 1 |


### Methodology

- 사용한 외부 라이브러리    
   1. konlpy  
   
      한글 자연어 처리를 쉽고 간결하게 처리할 수 있도록 만들어진 파이썬 패키지이다. 문장의 형태소 분석 및 단어 추출(Tokenizing)을 위해 konlpy 안에 있는 Okt 클래스를 이용하였다.  
   
   2. numpy, nltk  
   
      Dataset의 전처리(벡터화)를 위해 이용하였다. 벡터화는 텍스트 데이터를 머신러닝 알고리즘이 이해할 수 있는 수치 데이터로 변환하는 과정이다.
   
   3. tensorflow, keras  
   
      인공 신경망 모델의 생성 및 학습을 위해 이용하였다. loss function(실제 값과 예측 값의 차이(오차)를 계산하는 함수), optimizer(loss function(오차)를 최소화하는 가중치를 찾는 함수) 등을 추가해야 한다.
   
- 모델 생성 과정 및 이용  
   1. 데이터의 전처리 (형태소 분석 및 json 파일 생성) -> txt_preprocessing.py      
   
   ```python
   # Read txt file
   def read_data(txt_file):
       with open(txt_file, "r") as f:
           raw_data = f.read().splitlines()
           data = [line.split("\t") for line in raw_data]
           data = data[1:]
       return data
   ```
   txt 파일에서 학습 및 평가에 불필요한 id colomn을 제거하고, 각 문장마다 등장한 단어 목록 리스트, 긍정/부정 결과값으로
   이루어진 리스트를 만든다.
   
   ```python
   # Only word, except josa  
   # norm(normalization) : 표현 방법이 다른 단어들을 통합시켜서 같은 단어로 만들어줌, stem(stemming) : 어간 추출  
   def tokenize(doc):
       return [t[0] for t in parser.pos(doc, norm=True, stem=True)]
   
   # Read data and put it to raw_doc
   target = "txt_files/" + sys.argv[1] + ".txt"
   raw_doc = read_data(target)
   
   # Tokenized words and output result(0 or 1)
   data_set = [[tokenize(doc[1]), doc[2]] for doc in raw_doc]
   ```
   텍스트 파일을 불러온 후, 텍스트 데이터(영화 리뷰)에 대해 형태소 단위의 Tokenizing을 진행하고, Tokenizing 결과값과 긍정/부정 데이터를 data_set 리스트에 저장한다. Tokenizing 예시는 아래와 같다.
   
   ```python
   from konlpy.tag import Okt
   okt = Okt()
   print(okt.pos(u'이것도 되나욬ㅋㅋ'))
   print(okt.pos(u'이것도 되나욬ㅋㅋ', norm=True))
   print(okt.pos(u'이것도 되나욬ㅋㅋ', norm=True, stem=True))
   ```
   [('이', 'Determiner'), ('것', 'Noun'), ('도', 'Josa'), ('되나욬', 'Noun'), ('ㅋㅋ', 'KoreanParticle')]  
   [('이', 'Determiner'), ('것', 'Noun'), ('도', 'Josa'), ('되나요', 'Verb'), ('ㅋㅋ', 'KoreanParticle')]  
   [('이', 'Determiner'), ('것', 'Noun'), ('도', 'Josa'), ('되다', 'Verb'), ('ㅋㅋ', 'KoreanParticle')]  
   
   ```python
   # Make a json file
   file_name = "json_files/" + sys.argv[1] + "_dset.json"
   with open(file_name, "w") as make_file:
       json.dump(data_set, make_file, ensure_ascii=False, indent="  ")
   
   print("Preprocessing complete.")
   ```  
   학습 및 테스트를 위해 ratings_train.txt와 ratings_test.txt 두 파일에 대해 전처리를 진행하고, 두 개의 json 파일을 만든다.
   -> ratings_train_dset.json, ratings_test_dset.json
      
   내용 형태 -> [  [ [단어1, 단어2...] , 0 or 1 ] , [ [단어1, 단어2....] , 0 or 1 ] , ....... [ [단어1, 단어2] , 0 or 1 ]  ]  

   2. 데이터의 전처리 (Vectorization) -> learning_model.py  
   ```python
   target = "json_files/ratings_train_dset.json"
   # Loading json file
   with open(target) as f:
       train_target = json.load(f)
   ```
   ratings_train_dset.json 파일을 로드하고 그 내용을 train_target에 저장한다.
   
   ```python
   # Only tokens
   train_tokens = [tok for d in train_target for tok in d[0]]
   train_text = nltk.Text(train_tokens, name="train_t")   
   # Make selected_word <- This is used to make vector
   common_tests = train_text.vocab().most_common(100)
   selected_word = [word[0] for word in common_tests]
   ```
   벡터화를 위해 기준이 되는 단어 list를 만들어낸다. -> selected_word
   (train_target 전체에 등장한 단어들 중에서 등장 빈도수가 가장 높은 상위 100개의 단어들로 구성하였다.)

   ```python
   def term_frequency(doc):
       return [doc.count(s_word) for s_word in selected_word]
   
   # Vectorization
   # x is input (term), and it is dataset
   train_x = [term_frequency(d) for d, _ in train_target]
   # y is output (0 or 1), and it is dataset
   train_y = [c for _, c in train_target]
   ```
   그 후 term_frequency 함수를 통해 train_target 안의 각 문장 단어 리스트에서
   selected_word 안에 있는 단어의 등장 빈도를 나타내는 train_x(type: list)를 만든다.
   train_y는 train_target에 있는 긍정/부정 결과값들의 list이다.
   
   ```python
   # Change x and y to float type data
   train_x = np.asarray(train_x).astype("float32")
   train_y = np.asarray(train_y).astype("float32")
   ```
   마지막으로 train_x와 train_y 값을 float 형식으로 바꿔준다.
      
   3. 모델 생성 및 학습 -> learning_model.py  
   ```python
   # Initialize model
   model = models.Sequential()
   
   # Add layers to model(Output size, activation function, input size)
   model.add(layers.Dense(64, activation="relu", input_shape=(100,)))
   model.add(layers.Dense(64, activation="relu"))
   model.add(layers.Dense(1, activation="sigmoid"))
   ```
   Sequential로 model을 생성하고, 신경망 레이어를 3개 추가한다. 마지막 층(output layer)에서는 활성화 함수로 주로 이진 분류에 사용되는 sigmoid 함수를, 나머지 층에서는 hidden layer에서 주로 사용되는 활성화 함수인 relu 함수를 사용했다. 
   
   ```python
   # Set method of learning and evaluation (Gradient descent, error function, evaluation indicator)
   model.compile(optimizer=optimizers.RMSprop(lr=0.001),
                 loss=losses.binary_crossentropy,
                 metrics=[metrics.binary_accuracy])
   ```
   optimizer로는 경사 하강법의 일종인 RMSprop을 지정하였다. RMSprop을 사용하면 학습률(learning rate)이 계속해서 조정된다. 오차 함수는 이진 분류에 사용되는 binary_crossentropy를, 평가 지표로는 정확도를 지정하였다.

   ```python
   # Start learning (Input, output, number of trial, size of input at once
   model.fit(train_x, train_y, epochs=30, batch_size=1024)
   print("Learning complete.")
   ```

   입력, 출력 데이터(train_x, train_y)를 넣고 학습을 시작한다.  
   epoth(반복 횟수)는 30, batch_size(한번에 들어가는 입력의 크기)는 1024로 설정하였다.
   
   ```python
   # Save model
   c_time = datetime.datetime.now()
   cur_time = c_time.strftime("%Y_%m_%d_%H_%M_%S__")
   model_name = "NLP_model/learned_model.h5"
   model.save(model_name)
   # Save selected_word in json file
   with open("NLP_model/selected_word.json", "w") as sf:
       json.dump(selected_word, sf, ensure_ascii=False)
   print("Model is saved.")
   ```
   학습이 완료되면 모델(아키텍쳐 및 가중치 값 포함)을 h5 형식의 파일로 저장한다.
      
   4. 모델 평가 -> testing_model.py  
   ```python
   target_model = "NLP_model/learned_model.h5"
   target_json = "json_files/ratings_test_dset.json"
   # Load json file for test
   with open(target_json) as f:
       test_target = json.load(f)
   ```
   ```python
   # Load selected_word
   with open("NLP_model/selected_word.json", "r") as sf:
       selected_word = json.load(sf)
   # Load model
   model = load_model(target_model)
   ```
   학습 완료된 모델 및 ratings_tset_dset.json을 불러온다.  
   
   ```python
   def term_frequency(doc):
       return [doc.count(s_word) for s_word in selected_word]
   
   # Vectorization
   # x is input (term), and it is dataset
   test_x = [term_frequency(d) for d, _ in test_target]
   # y is output (0 or 1), and it is dataset
   test_y = [c for _, c in test_target]
   
   # Change x and y to float type data
   test_x = np.asarray(test_x).astype("float32")
   test_y = np.asarray(test_y).astype("float32")
   ```
   ```python
   # Evaluate model with test dataset
   result = model.evaluate(test_x, test_y)
   test_accuracy = result[1] * 100
   print("Accuracy is {:.2f}%".format(test_accuracy))
   ```
   
   evaluate()를 통해 테스트 데이터 셋에 대한 정확도를 측정한다.  
   실행 결과 77.96%의 정확도를 나타내었다.
         
   5. 모델의 활용 -> main_model.py  
   ```python  
   import json
   import numpy as np
   from konlpy.tag import Okt
   from keras.models import load_model
   
   parser = Okt()
   target_model = "NLP_model/learned_model.h5"
   
   # Load selected_word
   with open("NLP_model/selected_word.json", "r") as sf:
       selected_word = json.load(sf)
   # Load model
   model = load_model(target_model)
   ```
   ```python
   def tokenize(sentence):
       list = [t[0] for t in parser.pos(sentence, norm=True, stem=True)]
       return list
   
   
   # selected_word 안에 있는 word들이 각각 얼마나 나왔나
   def term_frequency(doc):
       return [doc.count(word) for word in selected_word]
   
   
   def calculate_sentiment_single_diary(sent):
       tokens = tokenize(sent)
       tf = term_frequency(tokens)
       data = np.expand_dims(np.asarray(tf).astype("float32"), axis=0)
       score = float(model.predict(data))
       if score > 0.5:
           return 1
       else:
           return 0
   ```
   calculate_sentiment_single_diary()를 포함하고 있다. Parameter 값으로 들어온 문장에 대해 감정 분석을 실시하고 결과값을 반환한다.


### Evaluation & Analysis

- learning_model.py에서 epoch 횟수의 변화에 따른 정확도의 변화 (testing_model.py 및 rating_test_dset.json으로 정확도를 평가하였다.)

   1. Epochs=20
   
      ![_config.yml]({{ site.baseurl }}/images/1.png) 
   
   2. Epochs=30
   
      ![_config.yml]({{ site.baseurl }}/images/2.png) 
   
   3. Epochs=50
   
      ![_config.yml]({{ site.baseurl }}/images/3.png) 
   
   4. Epochs=100
   
      ![_config.yml]({{ site.baseurl }}/images/4.png) 
   
   
   Epochs 횟수를 늘릴수록 overfitting 문제가 발생하여 정확도가 오히려 낮아지는 것을 관찰하였다. 따라서 정확도가 
   제일 양호한 epoch=20으로 설정하고 모델을 생성하였다.
   
- Input vector(selected_words)의 크기에 따른 정확도의 차이 -> Epochs=20을 기준으로 하였다.

   1. selected_words.length=500
   
      ![_config.yml]({{ site.baseurl }}/images/1.png) 
   
   2. selected_words.length=100
   
      ![_config.yml]({{ site.baseurl }}/images/1_1.png) 
      
      
   selected_words의 크기가 클 수록 정확도가 더 증가하였다.
   
- Epoch 횟수 결정 후 테스트용 문장 입력을 통한 모델의 정확도 평가

      ![_config.yml]({{ site.baseurl }}/images/긍정부정.png) 
   
   사용자의 감정과 문장 분석 결과값이 일치하게 나온다. 위 결과는 main_model.py를 수정하여 결과를 직접 나타낸 것으로, 실제 서버와 연동하여 
   동작할 경우에는 긍정일 경우 1을, 부정일 경우 0을 반환한다.

- 모델의 한계점

      ![_config.yml]({{ site.baseurl }}/images/애매쓰.png) 

   테스트용 데이터셋으로 평가한 정확도는 80.06%로 양호한 정확도였다. 그러나 입력받은 문장에 감정을 직접적으로 표현하는 단어가 없거나 
 모호할 경우에는 의도하지 않은 결과가 나오기도 하였다. 비록 사용자가 부정적인 감정으로 문장을 일기에 작성하였다고 할지라도, 감정의 
 표현이 모호할 경우에는 사용자의 실제 감정과는 다른 분석 결과를 반환하는 것이다.


### Related Work

- Libraries

   konlpy, numpy, nltk, tensorflow, keras

- Referenced blogs & documentations

   https://keras.io/getting-started/functional-api-guide/ -> 케라스 API 및 튜토리얼
   
   https://cyc1am3n.github.io/2018/11/10/classifying_korean_movie_review.html -> 네이버 영화 리뷰 감정분석 모델 구현을 참조
   
   https://konlpy-ko.readthedocs.io/ko/v0.4.3/ -> konlpy 라이브러리 API 및 튜토리얼
   
   https://www.slideshare.net/zzonee/2018-nlp-104155009 -> text data preprocessing에 관한 설명 참조
   
   https://www.slideshare.net/deepseaswjh/ss-155346055 -> 인공 신경망 구현에 관한 설명 및 튜토리얼

### Conclusion

 인공 신경망을 구성하고 모델을 생성하였고, 사용자가 기록한 일기의 내용을 바탕으로 사용자의 감정을 분석해낼 수 있도록 구현하였다. 학습의 횟수를 나타내는 epoch 값을 늘리면 그만큼 정확도가 증가할 것이라는 처음의 예상과는 다르게 epoch 값을 지나치게 높게 설정하면 overfitting이 발생하여 오히려 정확도가 떨어지는 것을 관찰하였다. 또한, 입력값이 되는 벡터의 크기를 늘림으로써 모델의 정확도를 높일 수 있다는 것을 관찰하였다.
   
 모델을 테스트 데이터 셋으로 평가한 결과 80.06%의 정확도를 얻어냈다. 높은 정확도로 거의 대부분의 문장에 성공적으로 감정 분석을
실시할 수 있을 줄 알았지만, 한계점 또한 명확하게 보였다. 하지만 위에서 언급한대로 한계점은 문장에서 감정의 표현이 모호할 경우에만
나타나며, 그 이외의 상황에서는 높은 확률로 감정 분석을 올바르게 수행할 수 있도록 구현하는 데에 성공하였다.
